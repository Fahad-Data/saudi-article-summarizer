from flask import Flask, request, jsonify
from flask_cors import CORS
import openai
import os
from datetime import datetime
import logging
import re
from typing import Dict, Any
import json
import requests
from bs4 import BeautifulSoup
from deep_translator import GoogleTranslator
import langdetect

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù€ crawler
from crawler import SaudiGazetteCrawler

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù€ logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Ø¥Ù†Ø´Ø§Ø¡ Flask app
app = Flask(__name__)
CORS(app)  # Ù„Ù„Ø³Ù…Ø§Ø­ Ø¨Ø·Ù„Ø¨Ø§Øª Ù…Ù† Frontend

# Ø¥Ø¹Ø¯Ø§Ø¯ OpenAI (ØªØ­ØªØ§Ø¬ ØªØ¶Ø¹ API key ÙÙŠ Ù…ØªØºÙŠØ± Ø§Ù„Ø¨ÙŠØ¦Ø©)
openai.api_key = os.getenv('OPENAI_API_KEY')

# Ø¥Ù†Ø´Ø§Ø¡ crawler instance
crawler = SaudiGazetteCrawler()

class ArticleFetcher:
    """Ø®Ø¯Ù…Ø© Ø¬Ù„Ø¨ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ù‚Ø§Ù„Ø§Øª Ù…Ù† Ø§Ù„Ø±ÙˆØ§Ø¨Ø·"""
    
    def __init__(self):
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
    
    def fetch_article_content(self, url: str) -> str:
        """Ø¬Ù„Ø¨ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ù‚Ø§Ù„ Ù…Ù† Ø§Ù„Ø±Ø§Ø¨Ø·"""
        try:
            response = requests.get(url, headers=self.headers, timeout=15)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ù‚Ø§Ù„ Ø¨Ø·Ø±Ù‚ Ù…ØªØ¹Ø¯Ø¯Ø©
            content = ""
            
            # Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰: Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† article tag
            article_tag = soup.find('article')
            if article_tag:
                # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¹Ù†Ø§ØµØ± ØºÙŠØ± Ø§Ù„Ù…Ø±ØºÙˆØ¨Ø©
                for unwanted in article_tag.find_all(['script', 'style', 'nav', 'aside', 'footer', 'header', 'iframe', 'noscript']):
                    unwanted.decompose()
                content = article_tag.get_text(separator=' ', strip=True)
            
            # Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ©: Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† div Ø¨Ù€ class Ù…Ø¹ÙŠÙ†
            if not content:
                content_divs = soup.find_all('div', class_=lambda x: x and any(
                    keyword in str(x).lower() for keyword in ['content', 'article', 'post', 'story', 'body', 'text', 'entry']
                ))
                for div in content_divs:
                    text = div.get_text(separator=' ', strip=True)
                    if len(text) > len(content):
                        content = text
            
            # Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø«Ø§Ù„Ø«Ø©: Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† main tag
            if not content:
                main_tag = soup.find('main')
                if main_tag:
                    content = main_tag.get_text(separator=' ', strip=True)
            
            # Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø±Ø§Ø¨Ø¹Ø©: Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† p tags
            if not content:
                paragraphs = soup.find_all('p')
                content = ' '.join([p.get_text(strip=True) for p in paragraphs if len(p.get_text(strip=True)) > 20])
            
            # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ
            content = re.sub(r'\s+', ' ', content).strip()
            content = re.sub(r'[^\w\s\u0600-\u06FF\u0750-\u077F\u08A0-\u08FF\uFB50-\uFDFF\uFE70-\uFEFF.,!?;:()\-"]', '', content)
            
            # Ù‚Ø·Ø¹ Ø§Ù„Ù†Øµ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø·ÙˆÙŠÙ„Ø§Ù‹ Ø¬Ø¯Ø§Ù‹
            if len(content) > 4000:
                content = content[:4000] + "..."
            
            return content if len(content) > 100 else None
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ù‚Ø§Ù„: {e}")
            return None

class TranslationService:
    """Ø®Ø¯Ù…Ø© Ø§Ù„ØªØ±Ø¬Ù…Ø© Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠØ©"""
    
    def __init__(self):
        self.translator = GoogleTranslator(source='auto', target='ar')
        self.arabic_keywords = ['Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©', 'Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©', 'Ø§Ù„Ø®Ù„ÙŠØ¬', 'Ø§Ù„Ø´Ø±Ù‚ Ø§Ù„Ø£ÙˆØ³Ø·', 'Ù…ÙƒØ©', 'Ø§Ù„Ø±ÙŠØ§Ø¶', 'Ø¬Ø¯Ø©']
    
    def detect_language(self, text: str) -> str:
        """Ø§ÙƒØªØ´Ø§Ù Ù„ØºØ© Ø§Ù„Ù†Øµ"""
        try:
            # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ Ø£ÙˆÙ„Ø§Ù‹
            clean_text = re.sub(r'[^\w\s]', ' ', text)[:100]  # Ø£ÙˆÙ„ 100 Ø­Ø±Ù ÙÙ‚Ø· Ù„Ù„Ø§ÙƒØªØ´Ø§Ù
            
            detected = langdetect.detect(clean_text)
            logger.info(f"Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…ÙƒØªØ´ÙØ©: {detected}")
            return detected
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ù„ØºØ©: {e}")
            # Ø¥Ø°Ø§ ÙØ´Ù„ Ø§Ù„Ø§ÙƒØªØ´Ø§ÙØŒ Ù†ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø£Ø­Ø±Ù Ø¹Ø±Ø¨ÙŠØ©
            arabic_chars = re.findall(r'[\u0600-\u06FF]', text)
            if len(arabic_chars) > 10:
                return 'ar'
            return 'en'
    
    def translate_to_arabic(self, text: str) -> tuple[str, bool]:
        """ØªØ±Ø¬Ù…Ø© Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±"""
        try:
            if not text or not text.strip():
                return text, False
            
            detected_lang = self.detect_language(text)
            
            # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù†Øµ Ø¹Ø±Ø¨ÙŠ Ø£ØµÙ„Ø§Ù‹ØŒ Ù„Ø§ Ù†ØªØ±Ø¬Ù…
            if detected_lang == 'ar':
                logger.info("Ø§Ù„Ù†Øµ Ø¹Ø±Ø¨ÙŠ Ø£ØµÙ„Ø§Ù‹ØŒ Ù„Ø§ Ø­Ø§Ø¬Ø© Ù„Ù„ØªØ±Ø¬Ù…Ø©")
                return text, False
            
            logger.info(f"ØªØ±Ø¬Ù…Ø© Ø§Ù„Ù†Øµ Ù…Ù† {detected_lang} Ø¥Ù„Ù‰ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©...")
            
            # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ø£Ø¬Ø²Ø§Ø¡ ØµØºÙŠØ±Ø© Ù„Ù„ØªØ±Ø¬Ù…Ø©
            chunks = self._split_text(text, 4000)  # Ø­Ø¯ Ø£Ø¹Ù„Ù‰ Ù„Ù„Ù€ deep-translator
            translated_chunks = []
            
            for chunk in chunks:
                try:
                    # Ø¥Ù†Ø´Ø§Ø¡ translator Ø¬Ø¯ÙŠØ¯ Ù„ÙƒÙ„ chunk
                    translator = GoogleTranslator(source=detected_lang, target='ar')
                    result = translator.translate(chunk)
                    translated_chunks.append(result)
                except Exception as e:
                    logger.warning(f"ÙØ´Ù„ ÙÙŠ ØªØ±Ø¬Ù…Ø© Ø¬Ø²Ø¡ Ù…Ù† Ø§Ù„Ù†Øµ: {e}")
                    # ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„ÙØ´Ù„ØŒ Ù†Ø­ØªÙØ¸ Ø¨Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ
                    translated_chunks.append(chunk)
            
            translated_text = ' '.join(translated_chunks)
            logger.info("ØªÙ… Ø¥ÙƒÙ…Ø§Ù„ Ø§Ù„ØªØ±Ø¬Ù…Ø© Ø¨Ù†Ø¬Ø§Ø­")
            return translated_text, True
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ±Ø¬Ù…Ø©: {e}")
            return text, False
    
    def _split_text(self, text: str, max_length: int) -> list:
        """ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ø£Ø¬Ø²Ø§Ø¡ ØµØºÙŠØ±Ø©"""
        if len(text) <= max_length:
            return [text]
        
        chunks = []
        sentences = re.split(r'[.!?]', text)
        current_chunk = ""
        
        for sentence in sentences:
            if len(current_chunk + sentence) <= max_length:
                current_chunk += sentence + ". "
            else:
                if current_chunk:
                    chunks.append(current_chunk.strip())
                current_chunk = sentence + ". "
        
        if current_chunk:
            chunks.append(current_chunk.strip())
        
        return chunks

class AIService:
    """Ø®Ø¯Ù…Ø© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù„Ù„ØªÙ„Ø®ÙŠØµ Ù…Ø¹ Ø§Ù„ØªØ±Ø¬Ù…Ø© Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠØ©"""
    
    def __init__(self):
        self.max_text_length = 8000
        self.article_fetcher = ArticleFetcher()
        self.translation_service = TranslationService()
        
    def _clean_text(self, text: str) -> str:
        """ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„Ø¹Ù†Ø§ØµØ± ØºÙŠØ± Ø§Ù„Ù…Ø±ØºÙˆØ¨Ø©"""
        # Ø¥Ø²Ø§Ù„Ø© HTML tags Ø¥Ø°Ø§ ÙˆØ¬Ø¯Øª
        text = re.sub(r'<[^>]+>', '', text)
        # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ø³Ø·Ø± Ø§Ù„ÙØ§Ø±ØºØ© Ø§Ù„Ø²Ø§Ø¦Ø¯Ø©
        text = re.sub(r'\n\s*\n', '\n\n', text)
        # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø§Ù„Ø²Ø§Ø¦Ø¯Ø©
        text = re.sub(r'\s+', ' ', text).strip()
        # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ø­Ø±Ù Ø§Ù„Ø®Ø§ØµØ© Ø§Ù„Ù…Ø´ÙƒÙˆÙƒ ÙÙŠÙ‡Ø§
        text = re.sub(r'[^\w\s\u0600-\u06FF\u0750-\u077F\u08A0-\u08FF\uFB50-\uFDFF\uFE70-\uFEFF.,!?;:()\-"Â»Â«]', '', text)
        return text
    
    def _validate_input(self, text: str) -> tuple[bool, str]:
        """ÙØ­Øµ ØµØ­Ø© Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø¯Ø®Ù„"""
        if not text or not text.strip():
            return False, "Ø§Ù„Ù†Øµ ÙØ§Ø±Øº"
        
        if len(text) > self.max_text_length:
            return False, f"Ø§Ù„Ù†Øµ Ø·ÙˆÙŠÙ„ Ø¬Ø¯Ø§Ù‹. Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ {self.max_text_length} Ø­Ø±Ù"
        
        if len(text.strip()) < 30:
            return False, "Ø§Ù„Ù†Øµ Ù‚ØµÙŠØ± Ø¬Ø¯Ø§Ù‹ Ù„Ù„ØªÙ„Ø®ÙŠØµ"
        
        return True, "Ø§Ù„Ù†Øµ ØµØ§Ù„Ø­"
    
    def _generate_simple_summary(self, text: str) -> str:
        """ØªÙˆÙ„ÙŠØ¯ Ù…Ù„Ø®Øµ Ø¨Ø³ÙŠØ· Ø¨Ø¯ÙˆÙ† AI APIs - Ù…Ø­Ø³Ù†"""
        try:
            # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ Ø£ÙˆÙ„Ø§Ù‹
            cleaned_text = self._clean_text(text)
            
            # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ø¬Ù…Ù„
            sentences = re.split(r'[.!?ØŸ]+', cleaned_text)
            sentences = [s.strip() for s in sentences if len(s.strip()) > 40]
            
            if len(sentences) == 0:
                return "Ù„Ù… ÙŠØªÙ…ÙƒÙ† Ù…Ù† Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ù„Ø®Øµ Ù…ÙÙŠØ¯ Ù…Ù† Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø¹Ø·Ù‰."
            
            # ØªØ­Ø¯ÙŠØ¯ Ø¹Ø¯Ø¯ Ø§Ù„Ø¬Ù…Ù„ Ù„Ù„Ù…Ù„Ø®Øµ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø·ÙˆÙ„ Ø§Ù„Ù†Øµ
            if len(sentences) <= 3:
                summary_sentences = sentences
            elif len(sentences) <= 8:
                # Ø£ÙˆÙ„ Ø¬Ù…Ù„ØªÙŠÙ† ÙˆØ¢Ø®Ø± Ø¬Ù…Ù„ØªÙŠÙ†
                summary_sentences = sentences[:2] + sentences[-2:]
            else:
                # Ø£ÙˆÙ„ Ø¬Ù…Ù„Ø©ØŒ Ø¬Ù…Ù„ØªÙŠÙ† Ù…Ù† Ø§Ù„ÙˆØ³Ø·ØŒ Ø¢Ø®Ø± Ø¬Ù…Ù„Ø©
                mid_start = len(sentences) // 3
                mid_end = 2 * len(sentences) // 3
                summary_sentences = [sentences[0]] + sentences[mid_start:mid_start+2] + [sentences[-1]]
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ù„Ø®Øµ
            summary = '. '.join(summary_sentences)
            if not summary.endswith('.'):
                summary += '.'
            
            # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ù…Ù„Ø®Øµ Ù„ÙŠØ³ Ù‚ØµÙŠØ±Ø§Ù‹ Ø¬Ø¯Ø§Ù‹
            if len(summary) < 150 and len(sentences) > 3:
                # Ø¥Ø¶Ø§ÙØ© Ø¬Ù…Ù„Ø© Ø£Ø®Ø±Ù‰ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ù„Ø®Øµ Ù‚ØµÙŠØ±
                if len(sentences) >= 5:
                    summary = '. '.join(sentences[:4]) + '.'
            
            return summary
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªÙ„Ø®ÙŠØµ Ø§Ù„Ø¨Ø³ÙŠØ·: {e}")
            return "Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªÙ„Ø®ÙŠØµ. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰."
    
    def _extract_content_from_article_data(self, article_data: Dict) -> str:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ù…Ù† Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ù‚Ø§Ù„"""
        try:
            # Ø¬Ù…Ø¹ Ø§Ù„Ù†Øµ Ø§Ù„Ù…ØªØ§Ø­ Ù…Ù† Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ù‚Ø§Ù„
            content_parts = []
            
            if article_data.get('title'):
                content_parts.append(article_data['title'])
            
            if article_data.get('excerpt') and article_data['excerpt'] != "No excerpt available":
                content_parts.append(article_data['excerpt'])
            
            # Ù…Ø­Ø§ÙˆÙ„Ø© Ø¬Ù„Ø¨ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ÙƒØ§Ù…Ù„ Ù…Ù† Ø§Ù„Ø±Ø§Ø¨Ø·
            if article_data.get('link'):
                logger.info(f"Ù…Ø­Ø§ÙˆÙ„Ø© Ø¬Ù„Ø¨ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ù‚Ø§Ù„ Ù…Ù†: {article_data['link']}")
                full_content = self.article_fetcher.fetch_article_content(article_data['link'])
                if full_content:
                    content_parts.append(full_content)
                    logger.info("ØªÙ… Ø¬Ù„Ø¨ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ù‚Ø§Ù„ Ø¨Ù†Ø¬Ø§Ø­")
                else:
                    logger.warning("ÙØ´Ù„ ÙÙŠ Ø¬Ù„Ø¨ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ù‚Ø§Ù„ Ù…Ù† Ø§Ù„Ø±Ø§Ø¨Ø·")
            
            combined_content = '\n\n'.join(content_parts)
            return combined_content if len(combined_content.strip()) > 50 else None
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ù‚Ø§Ù„: {e}")
            return None
    
    def summarize_to_arabic(self, text: str, is_article_data: bool = False) -> Dict[str, Any]:
        """
        ØªÙ„Ø®ÙŠØµ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ù…Ø¹ Ø§Ù„ØªØ±Ø¬Ù…Ø© Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠØ©
        
        Args:
            text: Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø±Ø§Ø¯ ØªÙ„Ø®ÙŠØµÙ‡ Ø£Ùˆ JSON string Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ù‚Ø§Ù„
            is_article_data: Ù‡Ù„ Ø§Ù„Ù†Øµ Ø¹Ø¨Ø§Ø±Ø© Ø¹Ù† Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù‚Ø§Ù„
            
        Returns:
            dict: ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù„Ø®Øµ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø£Ùˆ Ø±Ø³Ø§Ù„Ø© Ø®Ø·Ø£
        """
        try:
            # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù†Øµ Ø¹Ø¨Ø§Ø±Ø© Ø¹Ù† Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù‚Ø§Ù„
            actual_text = text
            if is_article_data:
                try:
                    article_data = json.loads(text) if isinstance(text, str) else text
                    extracted_content = self._extract_content_from_article_data(article_data)
                    if extracted_content:
                        actual_text = extracted_content
                    else:
                        return {
                            "success": False,
                            "error": "Ù„Ù… ÙŠØªÙ…ÙƒÙ† Ù…Ù† Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø­ØªÙˆÙ‰ ÙƒØ§ÙÙ Ù„Ù„ØªÙ„Ø®ÙŠØµ",
                            "summary_ar": None
                        }
                except Exception as e:
                    logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ù‚Ø§Ù„: {e}")
                    actual_text = text
            
            # ØªÙ†Ø¸ÙŠÙ ÙˆÙØ­Øµ Ø§Ù„Ù†Øµ
            cleaned_text = self._clean_text(actual_text)
            
            # Ø§Ù„ØªØ±Ø¬Ù…Ø© Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠØ© Ø¥Ù„Ù‰ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±
            translated_text, was_translated = self.translation_service.translate_to_arabic(cleaned_text)
            
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Øµ Ø§Ù„Ù…ØªØ±Ø¬Ù… Ù„Ù„ØªÙ„Ø®ÙŠØµ
            final_text = translated_text
            
            is_valid, validation_message = self._validate_input(final_text)
            
            if not is_valid:
                return {
                    "success": False,
                    "error": validation_message,
                    "summary_ar": None,
                    "was_translated": was_translated
                }
            
            summary = None
            method_used = "Unknown"
            
            # Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© 1: OpenAI GPT
            if openai.api_key and openai.api_key.strip():
                try:
                    logger.info("Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„ØªÙ„Ø®ÙŠØµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… OpenAI...")
                    
                    system_prompt = """Ø£Ù†Øª Ø®Ø¨ÙŠØ± ÙÙŠ ØªÙ„Ø®ÙŠØµ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¥Ø®Ø¨Ø§Ø±ÙŠØ© Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©. 
                    Ù…Ù‡Ù…ØªÙƒ Ù‡ÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø¹Ø·Ù‰ ÙˆÙƒØªØ§Ø¨Ø© Ù…Ù„Ø®Øµ Ø´Ø§Ù…Ù„ ÙˆØ¯Ù‚ÙŠÙ‚ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰.

                    Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„Ù…Ù„Ø®Øµ:
                    1. ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰
                    2. ÙŠØ¬Ø¨ Ø£Ù† ÙŠØºØ·ÙŠ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ÙÙŠ Ø§Ù„Ù†Øµ
                    3. ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† ÙˆØ§Ø¶Ø­Ø§Ù‹ ÙˆÙ…ÙÙ‡ÙˆÙ…Ø§Ù‹
                    4. ÙŠØ¬Ø¨ Ø£Ù† ÙŠØªØ±Ø§ÙˆØ­ Ø·ÙˆÙ„Ù‡ Ø¨ÙŠÙ† 150-300 ÙƒÙ„Ù…Ø©
                    5. ÙŠØ¬Ø¨ Ø£Ù† ÙŠØ­Ø§ÙØ¸ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ù†Ù‰ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ Ù„Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ
                    6. ØªØ¬Ù†Ø¨ Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø§Ù„ØµØºÙŠØ±Ø© ÙˆØ§Ù„ØªØ±ÙƒÙŠØ² Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‡Ù…
                    7. Ø§ÙƒØªØ¨ Ø¨Ø£Ø³Ù„ÙˆØ¨ ØµØ­ÙÙŠ ÙˆØ§Ø¶Ø­ ÙˆÙ…Ø¨Ø§Ø´Ø±
                    8. Ø§Ø³ØªØ®Ø¯Ù… Ø¬Ù…Ù„ ÙƒØ§Ù…Ù„Ø© ÙˆØªØ±Ø§ÙƒÙŠØ¨ Ø³Ù„ÙŠÙ…Ø©"""
                    
                    user_prompt = f"Ø§Ù„Ø±Ø¬Ø§Ø¡ ØªÙ„Ø®ÙŠØµ Ù‡Ø°Ø§ Ø§Ù„Ù†Øµ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©:\n\n{final_text}"
                    
                    response = openai.chat.completions.create(
                        model="gpt-4",
                        messages=[
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": user_prompt}
                        ],
                        max_tokens=400,
                        temperature=0.7
                    )
                    
                    summary = response.choices[0].message.content.strip()
                    method_used = "OpenAI GPT-4"
                    logger.info("ØªÙ… Ø§Ù„ØªÙ„Ø®ÙŠØµ Ø¨Ù†Ø¬Ø§Ø­ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… OpenAI")
                    
                except Exception as e:
                    logger.error(f"ÙØ´Ù„ OpenAI: {e}")
                    summary = None
            
            # Ø¥Ø°Ø§ Ù„Ù… ÙŠØªÙˆÙØ± OpenAI Ø£Ùˆ ÙØ´Ù„ØŒ Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„ØªÙ„Ø®ÙŠØµ Ø§Ù„Ø¨Ø³ÙŠØ·
            if not summary:
                logger.info("Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØªÙ„Ø®ÙŠØµ Ø§Ù„Ø¨Ø³ÙŠØ·...")
                summary = self._generate_simple_summary(final_text)
                method_used = "Simple Summary Algorithm"
            
            return {
                "success": True,
                "summary_ar": summary,
                "original_length": len(text),
                "summary_length": len(summary),
                "method_used": method_used,
                "was_translated": was_translated,
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªÙ„Ø®ÙŠØµ: {e}")
            return {
                "success": False,
                "error": f"Ø®Ø·Ø£ ÙÙŠ Ø®Ø¯Ù…Ø© Ø§Ù„ØªÙ„Ø®ÙŠØµ: {str(e)}",
                "summary_ar": None
            }

# Ø¥Ù†Ø´Ø§Ø¡ AI service instance
ai_service = AIService()

@app.route('/')
def health_check():
    """ÙØ­Øµ Ø­Ø§Ù„Ø© Ø§Ù„Ø®Ø§Ø¯Ù…"""
    return jsonify({
        "status": "running",
        "message": "Saudi Gazette Article Summarizer API with Auto Translation",
        "version": "2.0",
        "features": [
            "Article Crawling",
            "Auto Translation to Arabic",
            "AI-Powered Summarization",
            "Enhanced UI"
        ],
        "timestamp": datetime.now().isoformat()
    })

@app.route('/crawler/articles', methods=['GET'])
def get_articles():
    """
    GET /crawler/articles
    Ø¥Ø±Ø¬Ø§Ø¹ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ù‚Ø§Ù„Ø§Øª Ù…Ù† Saudi Gazette
    """
    try:
        # ÙØ­Øµ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙŠØ±ÙŠØ¯ Ø¥Ø¬Ø¨Ø§Ø± Ø§Ù„ØªØ­Ø¯ÙŠØ«
        force_refresh = request.args.get('force_refresh', 'false').lower() == 'true'
        
        # Ø¬Ù„Ø¨ Ø§Ù„Ù…Ù‚Ø§Ù„Ø§Øª
        articles = crawler.fetch_articles(force_refresh=force_refresh)
        
        return jsonify({
            "success": True,
            "articles": articles,
            "count": len(articles),
            "last_update": crawler.last_update.isoformat() if crawler.last_update else None,
            "cache_valid": crawler._is_cache_valid()
        })
        
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ù…Ù‚Ø§Ù„Ø§Øª: {e}")
        return jsonify({
            "success": False,
            "error": "Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ù…Ù‚Ø§Ù„Ø§Øª",
            "articles": []
        }), 500

@app.route('/articles/summarize', methods=['POST'])
def summarize_article():
    """
    POST /articles/summarize
    ØªÙ„Ø®ÙŠØµ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø±Ø³Ù„ Ø¥Ù„Ù‰ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ù…Ø¹ Ø§Ù„ØªØ±Ø¬Ù…Ø© Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠØ©
    
    Request body: {"text": "Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø±Ø§Ø¯ ØªÙ„Ø®ÙŠØµÙ‡"} Ø£Ùˆ {"article": {article_data}}
    Response: {"summary_ar": "Ø§Ù„Ù…Ù„Ø®Øµ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©", "was_translated": boolean}
    """
    try:
        # ÙØ­Øµ Content-Type
        if not request.is_json:
            return jsonify({
                "success": False,
                "error": "Content-Type ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† application/json"
            }), 400
        
        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        data = request.get_json()
        
        if not data:
            return jsonify({
                "success": False,
                "error": "Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…ÙÙ‚ÙˆØ¯Ø©"
            }), 400
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        if 'article' in data:
            # ØªÙ„Ø®ÙŠØµ Ù…Ù‚Ø§Ù„ Ù…Ø­Ø¯Ø¯
            article_data = data['article']
            result = ai_service.summarize_to_arabic(json.dumps(article_data), is_article_data=True)
        elif 'text' in data:
            # ØªÙ„Ø®ÙŠØµ Ù†Øµ Ù…Ø®ØµØµ
            text = data.get('text', '').strip()
            if not text:
                return jsonify({
                    "success": False,
                    "error": "Ø­Ù‚Ù„ 'text' Ù…Ø·Ù„ÙˆØ¨ ÙˆÙ„Ø§ ÙŠÙ…ÙƒÙ† Ø£Ù† ÙŠÙƒÙˆÙ† ÙØ§Ø±ØºØ§Ù‹"
                }), 400
            
            result = ai_service.summarize_to_arabic(text)
        else:
            return jsonify({
                "success": False,
                "error": "ÙŠØ¬Ø¨ Ø¥Ø±Ø³Ø§Ù„ 'text' Ø£Ùˆ 'article'"
            }), 400
        
        if not result["success"]:
            return jsonify({
                "success": False,
                "error": result["error"]
            }), 400
        
        # Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ù…Ù„Ø®Øµ
        return jsonify({
            "success": True,
            "summary_ar": result["summary_ar"],
            "was_translated": result.get("was_translated", False),
            "metadata": {
                "original_length": result.get("original_length"),
                "summary_length": result.get("summary_length"),
                "method_used": result.get("method_used"),
                "timestamp": result.get("timestamp")
            }
        })
        
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ endpoint Ø§Ù„ØªÙ„Ø®ÙŠØµ: {e}")
        return jsonify({
            "success": False,
            "error": "Ø®Ø·Ø£ Ø¯Ø§Ø®Ù„ÙŠ ÙÙŠ Ø§Ù„Ø®Ø§Ø¯Ù…"
        }), 500

@app.errorhandler(404)
def not_found(error):
    """Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„ØµÙØ­Ø§Øª ØºÙŠØ± Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©"""
    return jsonify({
        "success": False,
        "error": "Ø§Ù„ØµÙØ­Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©"
    }), 404

@app.errorhandler(500)
def internal_error(error):
    """Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ©"""
    return jsonify({
        "success": False,
        "error": "Ø®Ø·Ø£ Ø¯Ø§Ø®Ù„ÙŠ ÙÙŠ Ø§Ù„Ø®Ø§Ø¯Ù…"
    }), 500

if __name__ == '__main__':
    print("=" * 80)
    print("ğŸš€ Saudi Gazette Article Summarizer API v2.0")
    print("ğŸ”¥ NEW: Auto Translation to Arabic!")
    print("=" * 80)
    print("ğŸ“¡ Endpoints:")
    print("  GET  /                     - Health check")
    print("  GET  /crawler/articles     - Get articles from Saudi Gazette")
    print("  POST /articles/summarize   - Summarize text to Arabic (with auto translation)")
    print("=" * 80)
    print("ğŸ”§ Environment variables (optional):")
    print("  OPENAI_API_KEY - Ù„Ù„ØªÙ„Ø®ÙŠØµ Ø§Ù„Ù…ØªÙ‚Ø¯Ù… Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… GPT-4")
    print("=" * 80)
    print("âœ¨ NEW FEATURES:")
    print("  ğŸŒ Auto Translation: English â†’ Arabic")
    print("  ğŸ§  Enhanced AI Summarization")
    print("  ğŸ¨ Improved UI Components")
    print("  ğŸ” Better Content Extraction")
    print("=" * 80)
    print("ğŸ’¡ Ø§Ù„ØªÙ„Ø®ÙŠØµ Ø³ÙŠØ¹Ù…Ù„ Ø­ØªÙ‰ Ø¨Ø¯ÙˆÙ† API keys Ù…Ø¹ ØªØ±Ø¬Ù…Ø© ØªÙ„Ù‚Ø§Ø¦ÙŠØ©!")
    print("=" * 80)
    app.run(debug=True, host='0.0.0.0', port=5000)